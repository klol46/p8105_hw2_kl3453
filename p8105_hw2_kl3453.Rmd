---
title: "HW2: Markdown file"
author: "Kevin Liu"
date: "2023-09-30"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

# Problem 1

## First, clean the data in pols-month.csv. 

Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r}
pols_month_df = 
  read_csv("./data/pols-month.csv") |>
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), convert = TRUE) |> 
  mutate(month = month.abb[month]) |> 
  
  #This leaves leading zeros, which int will delete... but should be fine...
  mutate(year = substr(year,2,3)) |>  
  mutate(year = as.integer(year)) |> 
#Redundant code...I should have used "convert"!
  # separate(mon, into = c("year", "month_day"), sep = 4) |> 
  # mutate(year = as.numeric(year)) |> 
  # separate(month_day, into = c("month", "day"), sep = 3) |> 
  # mutate(month = substr(month, 2,3)) |> 
  # mutate(month = as.numeric(month)) |> 
  # mutate(month = month.name[month]) |> 
  # mutate(day = substr(day, 2,3)) |> 
  # mutate(day = as.numeric(day)) |> 

  mutate(president = if_else(prez_gop == 1 | prez_gop == 2, "gop", "dem")) |> 
  select(year, everything()) |> 
  select(-prez_gop, -prez_dem, -day)
#pols_month_df
```


## Second, clean the data in snp.csv using a similar process to the above. 

For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
snp_df = 
  read_csv("./data/snp.csv") |> 
  janitor::clean_names() |> 
  separate(date, into = c("month", "day", "year"), convert = TRUE) |> 
  mutate(month = month.abb[month]) |>
  select(-day) |> 
  select(year,everything())

#The way i did is not robust for the given date
  # separate(date, into = c("month", "day_year"), sep = 1) |> 
  # mutate(month = as.numeric(month)) |> 
  # mutate(month = month.name[month]) |> 
  # separate(day_year, into = c("day", "year"), sep = 2) |> 
  # select(-day) |> 
  # mutate(year = substr(year, 2,3)) |> 
  # mutate(year = if_else(grepl("/", year), substr(year,2,3), year))
  # mutate(year = as.numeric(year)) |> 
  # arrange(year)
#snp_df
```

## Third, tidy the unemployment data so that it can be merged with the previous datasets. 

This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
unemployment_df = 
  read_csv("./data/unemployment.csv") |> 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") |> 
  mutate(Year = substr(Year,3,4)) |> 
  rename("year" = "Year") |> 
  mutate(year = as.integer(year))
```

## Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
polls_snp_df = 
  left_join(pols_month_df, snp_df)

polls_snp_unem_df =
  left_join(polls_snp_df, unemployment_df)
```

### Write a short paragraph about these datasets. 

Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

__Response__
  The "pols" dataset contains 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time from 1947 to 2015. Of the 9 variables, 1 is the date, 4 variables enumerate how many presidents, govenors, senators, and representatives that are democrats, and the last 4 is the same enumeration but for repbulicans.
  The "snp" dataset contains 787 observations of 2 variables related to Standard & Poor’s stock market index (S&P). It contains a date variable and the S&P's closing value on that date from 1950 to 2015.
  The "unemployment" dataset contains 68 observations of 13 variables. The first column variable the year, denotes the year for the row while the next 12 column variables designates the month of that year. Within the cells are the unemployment rates for a partcular month in a year. During data processing, "unemployement" was long-ified and contains data from 1948 to 2015.
  The resulting dataset has a combination of all three datasets. "Unemployment" has been made long-ified in order to be properly merged with "pols" and "snp" based on month and year. It is a dataset with 822 observations and 11 variables where all three were merged based on year + month with close + unemployment being added to "pols" dataset.
  
# Problem 2

## Read and clean the Mr. Trash Wheel sheet:

*   specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures;  columns containing notes) using arguments in read_excel
*   use reasonable variable names
*   omit rows that do not include dumpster-specific data

```{r}
mr_trash_df =
  readxl::read_xlsx("./data/202207 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", skip = 1, n_max = 547) |> 
  janitor::clean_names() |> 
  mutate(dump_name = "mstr") |> 
  select(-x15, -x16) |> 
  select(dump_name, everything()) |> 
  mutate(year = as.double(year))
  
```

## Update the data to include a new homes_powered variable based on this calculation.
The data includes a column for the (approximate) number of homes powered. This calculation is described in the Homes powered note, but not applied to every row in the dataset.

*   Homes Powered - Each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day."

```{r}
mr_trash_df = 
  mutate(mr_trash_df, homes_powered = (weight_tons * 500) / 30)

```

## Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda.. 
and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

### Professor Trash Wheel
```{r}
prof_trash_df =
  readxl::read_xlsx("./data/202207 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", skip = 1, n_max = 94) |> 
  janitor::clean_names() |> 
  mutate(dump_name = "prof") |> 
  select(dump_name, everything())

```

### Gwynnda Trash Wheel
```{r}
gwynnda_trash_df =
  readxl::read_xlsx("./data/202207 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1, n_max = 107) |> 
  janitor::clean_names() |> 
  mutate(dump_name = "gwyn") |> 
  select(dump_name, everything())
```

### Merge All 3 Trash Wheels
```{r}
mstr_prof_gwynnda_df = 
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_trash_df)
```

## Write a paragraph about these data; you are encouraged to use inline R.

Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 

__Response__
  mr_trash_df contains the converted xlsx file to R studio dataframe data which has 548 observations of which are the days that the trash wheel was deployed and used. The amount of trash collected was enumerated (ie. weight_tons) and the types of trash collected where enumerated as well (ie. plastic_bottles) and a final "houses_powered" variable results as a way to measure the amount of trash collected. prof_trash_df and gwynna_trash_df are similar but contain 95 observations and 108 observations respectively. The final combination of the 3 contains the sum of the three separate dataframes as the dataframes are stacked together into one dataframe.
  
  
### For available data, what was the total weight of trash collected by Professor Trash Wheel? 

```{r}
sum(pull(mr_trash_df, weight_tons))
```

__Response__
  The total weight of trash collected by professor trash wheel was 3496.72 tons. 


### What was the total number of cigarette butts collected by Gwynnda in July of 2021?
```{r}
sum(pull(gwynnda_trash_df, cigarette_butts))
```

